"""
–î–∏—Å–ø–µ—Ç—á–µ—Ä —Ä–µ—Å—É—Ä—Å–æ–≤ GPU –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Ollama –∏ ComfyUI
"""
import asyncio
import heapq
import time
import uuid
import logging
from typing import Dict, Optional, List
from dataclasses import dataclass, field
from ..config import settings
from .vram_monitor import vram_monitor
from .service_types import ServiceType

logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º process_manager_service –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ServiceType
# —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
from .process_manager_service import process_manager_service


@dataclass
class GPURequest:
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU"""
    request_id: str
    service_type: ServiceType
    priority: int
    user_id: Optional[int]
    created_at: float
    required_vram_mb: Optional[int] = None
    
    def __lt__(self, other):
        """–î–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –æ—á–µ—Ä–µ–¥—å—é (heapq)"""
        # –í—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç = –º–µ–Ω—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –æ—á–µ—Ä–µ–¥–∏
        if self.priority != other.priority:
            return self.priority > other.priority  # –ë–æ–ª—å—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç = –º–µ–Ω—å—à–µ –≤ heap
        return self.created_at < other.created_at  # FIFO –¥–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞


@dataclass
class ResourceLock:
    """–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ GPU"""
    lock_id: str
    request: GPURequest
    acquired_at: float
    _released: bool = False
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await resource_manager.release_gpu(self.lock_id)


class ResourceManager:
    """–î–∏—Å–ø–µ—Ç—á–µ—Ä —Ä–µ—Å—É—Ä—Å–æ–≤ GPU"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self._lock = asyncio.Lock()  # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        self._gpu_lock: Optional[ResourceLock] = None  # –¢–µ–∫—É—â–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ GPU
        self._queue: List[GPURequest] = []  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è –æ—á–µ—Ä–µ–¥—å –∑–∞–ø—Ä–æ—Å–æ–≤
        self._active_locks: Dict[str, ResourceLock] = {}  # –ê–∫—Ç–∏–≤–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        self._wait_conditions: Dict[str, asyncio.Event] = {}  # –°–æ–±—ã—Ç–∏—è –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
        self.priority_comfyui = settings.GPU_PRIORITY_COMFYUI
        self.priority_ollama = settings.GPU_PRIORITY_OLLAMA
        self.wait_timeout = settings.GPU_WAIT_TIMEOUT
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        self._total_requests = 0
        self._total_timeouts = 0
        self._total_wait_time = 0.0
        self._total_usage_time = 0.0
        
        # Fallback —Ä–µ–∂–∏–º: –µ—Å–ª–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ VRAM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
        self._fallback_mode = False
        self._check_fallback_mode()
        
        logger.info("‚úÖ Resource Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def _check_fallback_mode(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback —Ä–µ–∂–∏–º"""
        vram_info = vram_monitor.get_vram_usage()
        if not vram_info.get("available"):
            self._fallback_mode = True
            logger.warning("‚ö†Ô∏è –†–µ–∂–∏–º fallback: –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ VRAM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ—Å—Ç–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞")
        else:
            self._fallback_mode = False
    
    def _get_priority(self, service_type: ServiceType) -> int:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Ç–∏–ø–∞ —Å–µ—Ä–≤–∏—Å–∞"""
        if service_type == ServiceType.COMFYUI:
            return self.priority_comfyui
        elif service_type == ServiceType.OLLAMA:
            return self.priority_ollama
        else:
            return 1
    
    async def acquire_gpu(
        self, 
        service_type: ServiceType, 
        user_id: Optional[int] = None,
        required_vram_mb: Optional[int] = None,
        timeout: Optional[int] = None
    ) -> ResourceLock:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É GPU –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞
        
        Args:
            service_type: –¢–∏–ø —Å–µ—Ä–≤–∏—Å–∞ (COMFYUI, OLLAMA, OTHER)
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            required_vram_mb: –¢—Ä–µ–±—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ VRAM –≤ –ú–ë (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            timeout: –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)
            
        Returns:
            ResourceLock –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ context manager
            
        Raises:
            TimeoutError: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –≤ —Ç–µ—á–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞
        """
        timeout = timeout or self.wait_timeout
        priority = self._get_priority(service_type)
        
        request = GPURequest(
            request_id=str(uuid.uuid4()),
            service_type=service_type,
            priority=priority,
            user_id=user_id,
            created_at=time.time(),
            required_vram_mb=required_vram_mb
        )
        
        self._total_requests += 1
        logger.info(f"üîÑ –ó–∞–ø—Ä–æ—Å GPU –¥–ª—è {service_type.value} (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}, ID: {request.request_id[:8]}, –≤—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {self._total_requests})")
        
        async with self._lock:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ —Å—Ä–∞–∑—É –ø–æ–ª—É—á–∏—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
            if self._gpu_lock is None:
                # –°–Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ –Ω—É–∂–Ω—ã–π —Å–µ—Ä–≤–∏—Å (—ç—Ç–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç VRAM)
                await self._switch_process_if_needed(service_type)
                
                # –ü–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å VRAM
                # –î–∞–µ–º –Ω–µ–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ VRAM –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
                await asyncio.sleep(2)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å VRAM (–∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –≤ fallback —Ä–µ–∂–∏–º–µ)
                if self._fallback_mode or vram_monitor.is_vram_available(required_vram_mb):
                    lock = ResourceLock(
                        lock_id=request.request_id,
                        request=request,
                        acquired_at=time.time()
                    )
                    self._gpu_lock = lock
                    self._active_locks[lock.lock_id] = lock
                    logger.info(f"‚úÖ GPU –≤—ã–¥–µ–ª–µ–Ω –¥–ª—è {service_type.value} (ID: {request.request_id[:8]})")
                    return lock
                else:
                    logger.info(f"‚è≥ VRAM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞, –æ–∂–∏–¥–∞–Ω–∏–µ...")
            
            # –ï—Å–ª–∏ GPU –∑–∞–Ω—è—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
            heapq.heappush(self._queue, request)
            wait_event = asyncio.Event()
            self._wait_conditions[request.request_id] = wait_event
            
            queue_position = len(self._queue)
            logger.info(f"üìã –ó–∞–ø—Ä–æ—Å –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å (–ø–æ–∑–∏—Ü–∏—è: {queue_position}, ID: {request.request_id[:8]})")
        
        # –ñ–¥–µ–º –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU –∏–ª–∏ —Ç–∞–π–º–∞—É—Ç–∞
        try:
            # –ñ–¥–µ–º –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è VRAM, –µ—Å–ª–∏ –æ–Ω–∞ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –≤ fallback —Ä–µ–∂–∏–º–µ)
            if not self._fallback_mode and not vram_monitor.is_vram_available(required_vram_mb):
                logger.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è VRAM...")
                vram_available = await vram_monitor.wait_for_vram(timeout, required_vram_mb)
                if not vram_available:
                    async with self._lock:
                        # –£–¥–∞–ª—è–µ–º –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                        self._queue = [r for r in self._queue if r.request_id != request.request_id]
                        if request.request_id in self._wait_conditions:
                            del self._wait_conditions[request.request_id]
                    raise TimeoutError(f"–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è VRAM ({timeout}s)")
            
            # –ñ–¥–µ–º –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU
            wait_start = time.time()
            await asyncio.wait_for(wait_event.wait(), timeout=timeout)
            
            async with self._lock:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—É—á–µ–Ω–∞
                if request.request_id in self._active_locks:
                    lock = self._active_locks[request.request_id]
                    wait_time = time.time() - wait_start
                    self._total_wait_time += wait_time
                    
                    # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ –Ω—É–∂–Ω—ã–π —Å–µ—Ä–≤–∏—Å (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω)
                    await self._switch_process_if_needed(service_type)
                    
                    # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ VRAM
                    await asyncio.sleep(2)
                    
                    logger.info(f"‚úÖ GPU –ø–æ–ª—É—á–µ–Ω –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è {wait_time:.1f}s –¥–ª—è {service_type.value} (ID: {request.request_id[:8]}, —Å—Ä–µ–¥–Ω–µ–µ –æ–∂–∏–¥–∞–Ω–∏–µ: {self._total_wait_time / max(1, self._total_requests - self._total_timeouts):.1f}s)")
                    return lock
                else:
                    raise RuntimeError("–ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –±—ã–ª–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                    
        except asyncio.TimeoutError:
            async with self._lock:
                # –£–¥–∞–ª—è–µ–º –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                self._queue = [r for r in self._queue if r.request_id != request.request_id]
                if request.request_id in self._wait_conditions:
                    del self._wait_conditions[request.request_id]
            
            wait_time = time.time() - wait_start
            self._total_timeouts += 1
            logger.warning(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU ({timeout}s) –¥–ª—è {service_type.value} (ID: {request.request_id[:8]}, –≤—Å–µ–≥–æ —Ç–∞–π–º–∞—É—Ç–æ–≤: {self._total_timeouts})")
            raise TimeoutError(f"–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU ({timeout}s)")
    
    async def release_gpu(self, lock_id: str):
        """
        –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É GPU
        
        Args:
            lock_id: ID –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è
        """
        async with self._lock:
            if lock_id not in self._active_locks:
                logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É: {lock_id[:8]}")
                return
            
            lock = self._active_locks[lock_id]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ç–µ–∫—É—â–∞—è –∞–∫—Ç–∏–≤–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞
            if self._gpu_lock and self._gpu_lock.lock_id == lock_id:
                service_type = lock.request.service_type.value
                usage_time = time.time() - lock.acquired_at
                self._total_usage_time += usage_time
                avg_usage = self._total_usage_time / max(1, self._total_requests - self._total_timeouts)
                logger.info(f"üîì GPU –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω –æ—Ç {service_type} (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {usage_time:.1f}s, ID: {lock_id[:8]}, —Å—Ä–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {avg_usage:.1f}s)")
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                await self._restore_previous_process()
                
                self._gpu_lock = None
                del self._active_locks[lock_id]
                lock._released = True
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—á–µ—Ä–µ–¥—å
                await self._process_queue()
            else:
                logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –Ω–µ–∞–∫—Ç–∏–≤–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É: {lock_id[:8]}")
    
    async def _process_queue(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å –∑–∞–ø—Ä–æ—Å–æ–≤"""
        while self._queue and self._gpu_lock is None:
            # –ë–µ—Ä–µ–º –∑–∞–ø—Ä–æ—Å —Å –Ω–∞–∏–≤—ã—Å—à–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
            request = heapq.heappop(self._queue)
            
            # –°–Ω–∞—á–∞–ª–∞ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ –Ω—É–∂–Ω—ã–π —Å–µ—Ä–≤–∏—Å (—ç—Ç–æ –æ—Å–≤–æ–±–æ–¥–∏—Ç VRAM)
            await self._switch_process_if_needed(request.service_type)
            
            # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ VRAM –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
            await asyncio.sleep(2)
            
            # –ü–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å VRAM
            if self._fallback_mode or vram_monitor.is_vram_available(request.required_vram_mb):
                lock = ResourceLock(
                    lock_id=request.request_id,
                    request=request,
                    acquired_at=time.time()
                )
                self._gpu_lock = lock
                self._active_locks[lock.lock_id] = lock
                
                # –£–≤–µ–¥–æ–º–ª—è–µ–º –æ–∂–∏–¥–∞—é—â–∏–π –∑–∞–ø—Ä–æ—Å
                if request.request_id in self._wait_conditions:
                    self._wait_conditions[request.request_id].set()
                    del self._wait_conditions[request.request_id]
                
                wait_time = time.time() - request.created_at
                logger.info(f"‚úÖ GPU –≤—ã–¥–µ–ª–µ–Ω –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –¥–ª—è {request.service_type.value} (–æ–∂–∏–¥–∞–Ω–∏–µ: {wait_time:.1f}s, ID: {request.request_id[:8]})")
                break
            else:
                # –ï—Å–ª–∏ VRAM –≤—Å–µ –µ—â–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–ø—Ä–æ—Å –≤ –æ—á–µ—Ä–µ–¥—å
                heapq.heappush(self._queue, request)
                logger.debug(f"‚è≥ VRAM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è {request.service_type.value} –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                break
    
    def get_queue_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –æ—á–µ—Ä–µ–¥–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º:
            {
                "gpu_locked": bool,
                "current_service": Optional[str],
                "queue_length": int,
                "queue": List[Dict],
                "vram_info": Dict
            }
        """
        vram_info = vram_monitor.get_vram_usage()
        
        async def _get_status():
            async with self._lock:
                current_service = None
                if self._gpu_lock:
                    current_service = self._gpu_lock.request.service_type.value
                
                queue_info = []
                for request in self._queue[:10]:  # –ü–µ—Ä–≤—ã–µ 10 –≤ –æ—á–µ—Ä–µ–¥–∏
                    queue_info.append({
                        "request_id": request.request_id[:8],
                        "service_type": request.service_type.value,
                        "priority": request.priority,
                        "waiting_time": time.time() - request.created_at
                    })
                
                return {
                    "gpu_locked": self._gpu_lock is not None,
                    "current_service": current_service,
                    "queue_length": len(self._queue),
                    "queue": queue_info,
                    "vram_info": vram_info,
                    "metrics": {
                        "total_requests": self._total_requests,
                        "total_timeouts": self._total_timeouts,
                        "timeout_rate": self._total_timeouts / max(1, self._total_requests),
                        "avg_wait_time": self._total_wait_time / max(1, self._total_requests - self._total_timeouts),
                        "avg_usage_time": self._total_usage_time / max(1, self._total_requests - self._total_timeouts),
                        "fallback_mode": self._fallback_mode
                    }
                }
        
        # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π event loop –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # –ï—Å–ª–∏ loop —É–∂–µ –∑–∞–ø—É—â–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, _get_status())
                    return future.result(timeout=1)
            else:
                return loop.run_until_complete(_get_status())
        except RuntimeError:
            # –ï—Å–ª–∏ –Ω–µ—Ç event loop, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            return asyncio.run(_get_status())
    
    async def _switch_process_if_needed(self, service_type: ServiceType):
        """
        –ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ –Ω—É–∂–Ω—ã–π —Å–µ—Ä–≤–∏—Å, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        
        Args:
            service_type: –¢–∏–ø —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Process Management API
        api_available = await process_manager_service.check_api_available()
        if not api_available:
            logger.warning("‚ö†Ô∏è Process Management API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞")
            return
        
        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å
        try:
            logger.info(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ –Ω–∞ {service_type.value}...")
            success = await process_manager_service.switch_to_service(service_type)
            if success:
                logger.info(f"‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω –Ω–∞ {service_type.value}")
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ {service_type.value}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –¥–∞–∂–µ –µ—Å–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å (fallback)
    
    async def _restore_previous_process(self):
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø—Ä–æ—Ü–µ—Å—Å –ø–æ—Å–ª–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU"""
        try:
            await process_manager_service.restore_previous_service()
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ): {e}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
resource_manager = ResourceManager()

