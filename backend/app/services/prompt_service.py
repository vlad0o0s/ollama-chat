"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
"""
import httpx
import json
import logging
import re
import base64
import asyncio
import time
from typing import Dict, Optional
from ..config import settings
from .resource_manager import resource_manager
from .service_types import ServiceType
from .process_manager_service import process_manager_service

logger = logging.getLogger(__name__)


class PromptService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏ —á–µ—Ä–µ–∑ Ollama"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Process Manager, Ollama –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ 127.0.0.1:11434
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ Process Manager (–µ—Å–ª–∏ PROCESS_MANAGER_API_URL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
        if settings.PROCESS_MANAGER_API_URL:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º localhost –¥–ª—è Process Manager
            self.ollama_url = "http://127.0.0.1:11434"
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º URL –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –ø—Ä—è–º–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            self.ollama_url = settings.OLLAMA_URL
        self.model = settings.OLLAMA_DEFAULT_MODEL
        # –ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –≤ –±—É–¥—É—â–µ–º)
        self._client_pool = None
    
    async def process_all_ollama_requests(
        self,
        image_bytes: Optional[bytes] = None,
        russian_description: str = "",
        user_id: Optional[int] = None
    ) -> Dict:
        """
        –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∫ Ollama –≤ –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏ GPU –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            image_bytes: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ LLaVA (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            russian_description: –û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            {
                "image_description": Optional[str],
                "prompt_result": Dict,
                "ksampler_result": Optional[Dict],
                "success": bool,
                "error": Optional[str]
            }
        """
        estimated_vram_mb = 6144  # 6GB –¥–ª—è llava:13b (–º–∞–∫—Å–∏–º—É–º)
        
        try:
            async with await resource_manager.acquire_gpu(
                service_type=ServiceType.OLLAMA,
                user_id=user_id,
                required_vram_mb=estimated_vram_mb,
                timeout=120  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            ) as gpu_lock:
                logger.info(f"üîí GPU –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è Ollama (–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã, ID: {gpu_lock.lock_id[:8]})")
                
                results = {
                    "image_description": None,
                    "prompt_result": None,
                    "ksampler_result": None,
                    "success": True,
                    "error": None
                }
                
                # 1. –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLaVA (–µ—Å–ª–∏ –µ—Å—Ç—å)
                # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –î–ª—è –ø–æ–ª–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É skip_gpu_lock –≤ analyze_image_with_vision
                if image_bytes:
                    logger.info(f"üîÑ [–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã] –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLaVA...")
                    # –í–ê–ñ–ù–û: –≠—Ç–æ—Ç –≤—ã–∑–æ–≤ —Å–æ–∑–¥–∞—Å—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É GPU
                    # –î–ª—è –ø–æ–ª–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å analyze_image_with_vision
                    vision_result = await self.analyze_image_with_vision(
                        image_bytes,
                        user_id=user_id
                    )
                    
                    if vision_result.get("success") and vision_result.get("description"):
                        results["image_description"] = vision_result.get("description")
                        logger.info(f"‚úÖ [–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã] –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ LLaVA")
                    else:
                        results["success"] = False
                        results["error"] = vision_result.get("error", "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                        return results
                
                # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤
                logger.info(f"üîÑ [–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã] –ü–µ—Ä–µ–≤–æ–¥ –æ–ø–∏—Å–∞–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç—ã...")
                prompt_result = await self.translate_and_enhance_prompt(
                    russian_description,
                    user_id=user_id,
                    image_description=results["image_description"],
                    skip_gpu_lock=True  # –£–∂–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ –≤ —ç—Ç–æ–º –º–µ—Ç–æ–¥–µ
                )
                
                if not prompt_result.get("success"):
                    results["success"] = False
                    results["error"] = prompt_result.get("error", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤")
                    return results
                
                results["prompt_result"] = prompt_result
                
                # 3. –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ KSampler (—Ç–æ–ª—å–∫–æ –¥–ª—è img-to-img)
                # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –î–ª—è –ø–æ–ª–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É skip_gpu_lock –≤ analyze_img2img_settings
                if image_bytes and results["image_description"]:
                    logger.info(f"üîÑ [–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã] –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ KSampler...")
                    # –í–ê–ñ–ù–û: –≠—Ç–æ—Ç –≤—ã–∑–æ–≤ —Å–æ–∑–¥–∞—Å—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É GPU
                    # –î–ª—è –ø–æ–ª–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å analyze_img2img_settings
                    ksampler_result = await self.analyze_img2img_settings(
                        russian_description,
                        user_id=user_id,
                        image_description=results["image_description"]
                    )
                    results["ksampler_result"] = ksampler_result
                
                logger.info(f"‚úÖ [–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã] –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∫ Ollama –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≤ –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏ GPU")
                return results
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö –∫ Ollama: {e}")
            return {
                "image_description": None,
                "prompt_result": None,
                "ksampler_result": None,
                "success": False,
                "error": str(e)
            }
        
    async def translate_and_enhance_prompt(self, russian_description: str, user_id: Optional[int] = None, image_description: Optional[str] = None, skip_gpu_lock: bool = False) -> Dict:
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ä—É—Å—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        
        Args:
            russian_description: –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏)
            image_description: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç LLaVA (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏:
            {
                "positive": str,  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
                "negative": str,  # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
                "success": bool,
                "error": Optional[str]
            }
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if image_description:
            system_prompt = f"""You are a professional prompt engineer for AI image generation using Flux model.
The user wants to modify an existing image based on their description.

CURRENT IMAGE DESCRIPTION (from visual analysis):
{image_description}

Your task is to translate the user's Russian description into a high-quality, detailed English prompt that will transform the current image according to the user's request.

IMPORTANT: You know what the current image looks like. The user wants to change it. Generate a prompt that describes the DESIRED RESULT, not the current state.

CRITICAL: If the user mentions COLOR CHANGES (e.g., "—Å–¥–µ–ª–∞—Ç—å –±–µ–ª—ã–π", "–∫—Ä–∞—Å–Ω—ã–π", "–∏–∑–º–µ–Ω–∏—Ç—å —Ü–≤–µ—Ç"), you MUST:
- Explicitly state the NEW color in the prompt multiple times for emphasis
- Use strong color descriptors (e.g., "pure white", "bright red", "vibrant blue")
- Include color in the main subject description
- Add color emphasis phrases like "the entire object is [color]", "completely [color] in color"
- If the current image has a different color, make sure to emphasize the NEW color strongly

Requirements for the positive prompt:
- Be detailed and specific
- For COLOR CHANGES: Emphasize the NEW color multiple times, use strong color words
- Describe the desired transformation based on the current image description
- Include style keywords (photorealistic, cinematic, artistic, etc.)
- Include composition details (close-up, wide shot, portrait, etc.)
- Include lighting details (natural lighting, studio lighting, golden hour, etc.)
- Include quality keywords (high quality, detailed, 8k, etc.)
- Use professional photography and art terminology
- Keep it concise but descriptive (50-150 words)

Requirements for the negative prompt:
- List common unwanted elements (blurry, low quality, distorted, etc.)
- If color change is requested, explicitly exclude the OLD color from the current image (e.g., if changing from black to white, exclude "black", "dark", "metallic black")
- Include specific exclusions based on the description context
- Keep it concise (20-50 words)

Return ONLY valid JSON in this exact format:
{{
  "positive": "detailed English prompt here",
  "negative": "unwanted elements here"
}}

Do not include any text before or after the JSON. Only return the JSON object."""
        else:
            system_prompt = """You are a professional prompt engineer for AI image generation using Flux model.
Your task is to translate the user's Russian description into a high-quality, detailed English prompt.

CRITICAL: If the user mentions COLOR CHANGES (e.g., "—Å–¥–µ–ª–∞—Ç—å –±–µ–ª—ã–π", "–∫—Ä–∞—Å–Ω—ã–π", "–∏–∑–º–µ–Ω–∏—Ç—å —Ü–≤–µ—Ç"), you MUST:
- Explicitly state the color in the prompt multiple times for emphasis
- Use strong color descriptors (e.g., "pure white", "bright red", "vibrant blue")
- Include color in the main subject description
- Add color emphasis phrases like "the entire object is [color]", "completely [color] in color"

Requirements for the positive prompt:
- Be detailed and specific
- For COLOR CHANGES: Emphasize the color multiple times, use strong color words
- Include style keywords (photorealistic, cinematic, artistic, etc.)
- Include composition details (close-up, wide shot, portrait, etc.)
- Include lighting details (natural lighting, studio lighting, golden hour, etc.)
- Include quality keywords (high quality, detailed, 8k, etc.)
- Use professional photography and art terminology
- Keep it concise but descriptive (50-150 words)

Requirements for the negative prompt:
- List common unwanted elements (blurry, low quality, distorted, etc.)
- If color change is requested, explicitly exclude the OLD color (e.g., if changing to white, exclude "brown", "gray", "metallic")
- Include specific exclusions based on the description context
- Keep it concise (20-50 words)

Return ONLY valid JSON in this exact format:
{
  "positive": "detailed English prompt here",
  "negative": "unwanted elements here"
}

Do not include any text before or after the JSON. Only return the JSON object."""
        
        # –ï—Å–ª–∏ skip_gpu_lock=True, –∑–Ω–∞—á–∏—Ç GPU —É–∂–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω (–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)
        if skip_gpu_lock:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ GPU
            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    return await self._execute_prompt_translation(client, russian_description, image_description)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤ (–±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ GPU): {e}")
                return {
                    "positive": "",
                    "negative": "",
                    "success": False,
                    "error": str(e)
                }
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç—Ä–µ–±—É–µ–º—É—é VRAM –¥–ª—è Ollama (–æ–±—ã—á–Ω–æ 2-4GB)
        # –£–º–µ–Ω—å—à–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–æ—Ü–µ—Å—Å –±—É–¥–µ—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
        estimated_vram_mb = 2048  # 2GB - –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ VRAM –±—É–¥–µ—Ç —Å–≤–æ–±–æ–¥–Ω–∞
        
        # –ü–æ–ª—É—á–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É GPU —á–µ—Ä–µ–∑ Resource Manager
        try:
            async with await resource_manager.acquire_gpu(
                service_type=ServiceType.OLLAMA,
                user_id=user_id,
                required_vram_mb=estimated_vram_mb,
                timeout=60
            ) as gpu_lock:
                logger.info(f"üîí GPU –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è Ollama (–ø–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–º–ø—Ç–∞, ID: {gpu_lock.lock_id[:8]})")
                
                try:
                    async with httpx.AsyncClient(timeout=60.0) as client:
                        return await self._execute_prompt_translation(client, russian_description, image_description)
                except httpx.TimeoutException:
                    logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama")
                    return {
                        "positive": "",
                        "negative": "",
                        "success": False,
                        "error": "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama"
                    }
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤: {e}")
                    return {
                        "positive": "",
                        "negative": "",
                        "success": False,
                        "error": str(e)
                    }
                    
        except TimeoutError as e:
            logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU –¥–ª—è Ollama (–ø–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–º–ø—Ç–∞): {e}")
            return {
                "positive": "",
                "negative": "",
                "success": False,
                "error": f"–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU: {str(e)}"
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Resource Manager: {e}")
            return {
                "positive": "",
                "negative": "",
                "success": False,
                "error": f"–û—à–∏–±–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–∞–º–∏: {str(e)}"
            }
    
    async def _execute_prompt_translation(self, client: httpx.AsyncClient, russian_description: str, image_description: Optional[str] = None) -> Dict:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–º–ø—Ç–∞ (–≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å/–±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ GPU)
        Flux.1-dev —Ç—Ä–µ–±—É–µ—Ç Natural Language –ø—Ä–æ–º–ø—Ç—ã
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # Flux.1-dev —Ç—Ä–µ–±—É–µ—Ç Natural Language –ø—Ä–æ–º–ø—Ç—ã, –∞ –Ω–µ tag-based
        if image_description:
            system_prompt = f"""You are an expert prompt engineer for the Flux.1 image generation model. Your goal is to create a single, cohesive descriptive paragraph in English based on the provided image analysis and the user's modification request.

CURRENT IMAGE DESCRIPTION (from LLaVA visual analysis):
{image_description}

CRITICAL INSTRUCTIONS:

1. Use Natural Language: Do NOT use tags, commas, or "keyword soup" (e.g., "black cat, 8k, sharp"). Write in full, descriptive sentences that flow naturally.

2. Prioritize User Requests: If the user asks for a "black cat" but LLaVA describes a "brown cat," the final prompt MUST describe a black cat. The user's request takes priority over the current image description.

3. Focus on Details: Describe lighting (e.g., "warm indoor glow"), textures (e.g., "glossy fur," "pine needles"), and interactions between objects.

4. Avoid Junk Words: Do NOT use "photorealistic," "ultra-detailed," "8k," "masterpiece," or similar quality tags. Flux does not need them and they can degrade results.

5. No Negative Prompting: Do NOT generate a negative prompt. Flux handles quality through the main description. Return an empty string for negative.

6. Output Format: Provide ONLY valid JSON with the final prompt text. No introduction or explanation.

Example:
Input - LLaVA: "A brown tabby cat reaching for gold ornaments on a green tree."
User: "Make it a black cat and use red ornaments."
Output: {{"positive": "A high-quality photo of a sleek black cat perched within the branches of a lush Christmas tree. The cat is playfully swatting at vibrant red spheres. Soft, golden holiday lights twinkle in the background, casting a gentle sheen on the cat's dark fur and the sharp green pine needles.", "negative": ""}}

Return ONLY valid JSON in this exact format:
{{
  "positive": "single cohesive descriptive paragraph in natural English",
  "negative": ""
}}

Do not include any text before or after the JSON. Only return the JSON object."""
        else:
            system_prompt = """You are an expert prompt engineer for the Flux.1 image generation model. Your goal is to create a single, cohesive descriptive paragraph in English based on the user's request.

CRITICAL INSTRUCTIONS:

1. Use Natural Language: Do NOT use tags, commas, or "keyword soup" (e.g., "black cat, 8k, sharp"). Write in full, descriptive sentences that flow naturally.

2. Focus on Details: Describe lighting (e.g., "warm indoor glow"), textures (e.g., "glossy fur," "pine needles"), and interactions between objects.

3. Avoid Junk Words: Do NOT use "photorealistic," "ultra-detailed," "8k," "masterpiece," or similar quality tags. Flux does not need them and they can degrade results.

4. No Negative Prompting: Do NOT generate a negative prompt. Flux handles quality through the main description. Return an empty string for negative.

5. Output Format: Provide ONLY valid JSON with the final prompt text. No introduction or explanation.

Return ONLY valid JSON in this exact format:
{
  "positive": "single cohesive descriptive paragraph in natural English",
  "negative": ""
}

Do not include any text before or after the JSON. Only return the JSON object."""

        if image_description:
            user_message = f"LLaVA analysis: {image_description}\n\nUser request: {russian_description}\n\nGenerate a natural language prompt for Flux.1 that transforms the image according to the user's request."
        else:
            user_message = f"User request: {russian_description}\n\nGenerate a natural language prompt for Flux.1 based on this description."
        
        payload = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_message
                }
            ],
            "stream": False,
            "format": "json"  # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º JSON —Ñ–æ—Ä–º–∞—Ç, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
        }
        
        response = await client.post(
            f"{self.ollama_url}/api/chat",
            json=payload
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result.get("message", {}).get("content", "")
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            try:
                # –£–±–∏—Ä–∞–µ–º markdown code blocks, –µ—Å–ª–∏ –µ—Å—Ç—å
                content = content.strip()
                if content.startswith("```"):
                    # –£–¥–∞–ª—è–µ–º ```json –∏ ``` –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
                    lines = content.split("\n")
                    if lines[0].startswith("```"):
                        lines = lines[1:]
                    if lines[-1].strip() == "```":
                        lines = lines[:-1]
                    content = "\n".join(lines)
                
                prompt_data = json.loads(content)
                
                positive = prompt_data.get("positive", "")
                negative = prompt_data.get("negative", "")
                
                if not positive:
                    raise ValueError("–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –ø—É—Å—Ç–æ–π")
                
                # –î–ª—è Flux.1-dev negative prompt –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—É—Å—Ç—ã–º
                # Flux –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç negative prompting, –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç
                negative = ""  # –í—Å–µ–≥–¥–∞ –ø—É—Å—Ç–æ–π –¥–ª—è Flux.1-dev
                
                # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º _enhance_color_change_prompts –¥–ª—è Flux.1-dev
                # –ü—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–º, –∞ –Ω–µ tag-based
                
                logger.info(f"‚úÖ –ü—Ä–æ–º–ø—Ç—ã —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
                return {
                    "positive": positive.strip(),
                    "negative": negative.strip(),
                    "success": True,
                    "error": None
                }
                
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Ollama: {e}")
                logger.debug(f"–û—Ç–≤–µ—Ç –æ—Ç Ollama: {content[:500]}")
                
                # Fallback: –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –ø—Ä–æ–º–ø—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
                return self._fallback_prompt_extraction(content, russian_description)
                
        else:
            error_msg = f"–û—à–∏–±–∫–∞ Ollama API: {response.status_code} - {response.text}"
            logger.error(f"‚ùå {error_msg}")
            return {
                "positive": "",
                "negative": "",
                "success": False,
                "error": error_msg
            }
    
    def _fallback_prompt_extraction(self, content: str, original_description: str) -> Dict:
        """
        Fallback –º–µ—Ç–æ–¥ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤, –µ—Å–ª–∏ JSON –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è
        
        Args:
            content: –û—Ç–≤–µ—Ç –æ—Ç Ollama
            original_description: –ò—Å—Ö–æ–¥–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–æ–º–ø—Ç–∞–º–∏
        """
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –∏—â–µ–º "positive" –∏ "negative" –≤ —Ç–µ–∫—Å—Ç–µ
        positive = ""
        negative = ""
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON-–ø–æ–¥–æ–±–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        # –ò—â–µ–º "positive": "..."
        positive_match = re.search(r'"positive"\s*:\s*"([^"]+)"', content, re.IGNORECASE)
        if positive_match:
            positive = positive_match.group(1)
        
        # –ò—â–µ–º "negative": "..."
        negative_match = re.search(r'"negative"\s*:\s*"([^"]+)"', content, re.IGNORECASE)
        if negative_match:
            negative = negative_match.group(1)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥
        if not positive:
            # –ü—Ä–æ—Å—Ç–æ–π fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∫ –µ—Å—Ç—å
            # (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫)
            positive = original_description
            logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback: –∏—Å—Ö–æ–¥–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞")
        
        # –î–ª—è Flux.1-dev negative prompt –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—É—Å—Ç—ã–º
        negative = ""  # –í—Å–µ–≥–¥–∞ –ø—É—Å—Ç–æ–π –¥–ª—è Flux.1-dev
        
        # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º _enhance_color_change_prompts –¥–ª—è Flux.1-dev
        # –ü—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–º
        
        return {
            "positive": positive.strip(),
            "negative": "",  # –í—Å–µ–≥–¥–∞ –ø—É—Å—Ç–æ–π –¥–ª—è Flux.1-dev
            "success": True,
            "error": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback –º–µ—Ç–æ–¥ (JSON –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è)"
        }
    
    def _enhance_color_change_prompts(self, positive: str, negative: str, russian_description: str) -> tuple:
        """
        –£—Å–∏–ª–∏–≤–∞–µ—Ç –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–≤–µ—Ç–∞, –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
        
        Args:
            positive: –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            negative: –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            russian_description: –ò—Å—Ö–æ–¥–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (enhanced_positive, enhanced_negative)
        """
        description_lower = russian_description.lower()
        
        # –°–ª–æ–≤–∞—Ä—å —Ü–≤–µ—Ç–æ–≤: —Ä—É—Å—Å–∫–∏–π -> –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
        color_map = {
            "–±–µ–ª—ã–π": "white",
            "–∫—Ä–∞—Å–Ω—ã–π": "red",
            "—Å–∏–Ω–∏–π": "blue",
            "—á–µ—Ä–Ω—ã–π": "black",
            "–∑–µ–ª–µ–Ω—ã–π": "green",
            "–∂–µ–ª—Ç—ã–π": "yellow",
            "–æ—Ä–∞–Ω–∂–µ–≤—ã–π": "orange",
            "—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π": "purple",
            "—Ä–æ–∑–æ–≤—ã–π": "pink",
            "–∫–æ—Ä–∏—á–Ω–µ–≤—ã–π": "brown",
            "—Å–µ—Ä—ã–π": "gray",
            "–≥–æ–ª—É–±–æ–π": "light blue",
            "–±–µ–∂–µ–≤—ã–π": "beige",
            "–∑–æ–ª–æ—Ç–æ–π": "golden",
            "—Å–µ—Ä–µ–±—Ä—è–Ω—ã–π": "silver"
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞
        detected_colors = []
        for ru_color, en_color in color_map.items():
            if ru_color in description_lower:
                detected_colors.append((ru_color, en_color))
        
        # –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞, —É—Å–∏–ª–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç
        if detected_colors:
            logger.info(f"üé® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞: {[c[1] for c in detected_colors]}")
            
            for ru_color, en_color in detected_colors:
                # –£—Å–∏–ª–∏–≤–∞–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                color_phrases = [
                    f"completely {en_color} in color",
                    f"entirely {en_color}",
                    f"pure {en_color}",
                    f"fully {en_color}",
                    f"the entire object is {en_color}"
                ]
                
                # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–∏–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞, –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç –≤ –ø—Ä–æ–º–ø—Ç–µ
                en_color_lower = en_color.lower()
                if en_color_lower not in positive.lower():
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ü–≤–µ—Ç –≤ –Ω–∞—á–∞–ª–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–∫—Ü–µ–Ω—Ç–∞
                    positive = f"{en_color.capitalize()} color, " + positive
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è
                for phrase in color_phrases[:2]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 —Ñ—Ä–∞–∑—ã
                    if phrase.lower() not in positive.lower():
                        positive += f", {phrase}"
                
                # –£—Å–∏–ª–∏–≤–∞–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç - –∏—Å–∫–ª—é—á–∞–µ–º –¥—Ä—É–≥–∏–µ —Ü–≤–µ—Ç–∞
                other_colors = [c[1] for c in detected_colors if c[1] != en_color]
                for other_color in other_colors:
                    if other_color.lower() not in negative.lower():
                        negative += f", {other_color}"
                
                # –ò—Å–∫–ª—é—á–∞–µ–º –æ–±—â–∏–µ —Ü–≤–µ—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –º–µ—à–∞—Ç—å
                conflicting_colors = ["brown", "gray", "metallic", "silver", "gold"]
                if en_color.lower() not in [c.lower() for c in conflicting_colors]:
                    for conf_color in conflicting_colors:
                        if conf_color.lower() not in negative.lower():
                            negative += f", {conf_color}"
        
        return positive, negative
    
    def _validate_image_description(self, description: str) -> Dict[str, any]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω–æ—Ç—É –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            description: –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç LLaVA
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –ø—Ä–æ–≤–µ—Ä–∫–∏:
            {
                "complete": bool,
                "missing_categories": List[str],
                "has_colors": bool,
                "has_materials": bool,
                "has_objects": bool
            }
        """
        description_lower = description.lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        color_keywords = ["color", "colour", "red", "blue", "green", "yellow", "white", "black", "brown", "gray", "grey", "pink", "orange", "purple", "shade", "tone", "bright", "dark", "light"]
        material_keywords = ["wood", "metal", "plastic", "fabric", "stone", "glass", "concrete", "texture", "smooth", "rough", "glossy", "matte", "reflective", "porous"]
        object_keywords = ["object", "item", "thing", "fence", "wall", "building", "tree", "car", "person", "animal", "structure"]
        
        has_colors = any(keyword in description_lower for keyword in color_keywords)
        has_materials = any(keyword in description_lower for keyword in material_keywords)
        has_objects = any(keyword in description_lower for keyword in object_keywords)
        
        missing_categories = []
        if not has_colors:
            missing_categories.append("colors")
        if not has_materials:
            missing_categories.append("materials")
        if not has_objects:
            missing_categories.append("objects")
        
        complete = len(missing_categories) == 0
        
        return {
            "complete": complete,
            "missing_categories": missing_categories,
            "has_colors": has_colors,
            "has_materials": has_materials,
            "has_objects": has_objects
        }
    
    async def analyze_image_with_vision(self, image_bytes: bytes, user_id: Optional[int] = None) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ LLaVA –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        
        Args:
            image_bytes: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ bytes
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º:
            {
                "description": str,  # –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
                "success": bool,
                "error": Optional[str]
            }
        """
        try:
            # –°–∂–∏–º–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ LLaVA, —á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–∞–¥–µ–Ω–∏–µ Ollama –∏–∑-–∑–∞ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            from PIL import Image
            from io import BytesIO
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ magic bytes (–¥–æ —Å–∂–∞—Ç–∏—è)
            image_format = "png"
            if image_bytes.startswith(b'\xff\xd8\xff'):
                image_format = "jpeg"
            elif image_bytes.startswith(b'\x89PNG'):
                image_format = "png"
            elif image_bytes.startswith(b'RIFF') and b'WEBP' in image_bytes[:12]:
                image_format = "webp"
            
            try:
                image = Image.open(BytesIO(image_bytes))
                original_width, original_height = image.size
                
                # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è LLaVA (—É–º–µ–Ω—å—à–∞–µ–º –¥–æ 768px –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)
                max_size_for_llava = 768
                max_dimension = max(original_width, original_height)
                
                if max_dimension > max_size_for_llava:
                    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
                    if original_width > original_height:
                        new_width = max_size_for_llava
                        new_height = int(original_height * (max_size_for_llava / original_width))
                    else:
                        new_height = max_size_for_llava
                        new_width = int(original_width * (max_size_for_llava / original_height))
                    
                    # –°–∂–∏–º–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ bytes —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
                    output = BytesIO()
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º JPEG –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–∂–∞—Ç–∏—è (–µ—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏)
                    has_transparency = image.mode in ('RGBA', 'LA') or (hasattr(image, 'info') and 'transparency' in image.info)
                    if not has_transparency:
                        resized_image = resized_image.convert('RGB')
                        resized_image.save(output, format='JPEG', quality=85, optimize=True)
                        image_format = "jpeg"
                    else:
                        resized_image.save(output, format='PNG', optimize=True)
                        image_format = "png"
                    
                    image_bytes = output.getvalue()
                    logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–∂–∞—Ç–æ –¥–ª—è LLaVA: {original_width}x{original_height} -> {new_width}x{new_height} (—Ä–∞–∑–º–µ—Ä: {len(image_bytes)} –±–∞–π—Ç)")
                else:
                    logger.debug(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {original_width}x{original_height} –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Å–∂–∞—Ç–∏—è –¥–ª—è LLaVA")
            except Exception as resize_error:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∂–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è LLaVA: {resize_error}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
            base64_image = base64.b64encode(image_bytes).decode('utf-8')
            logger.debug(f"üìä –†–∞–∑–º–µ—Ä base64 –¥–ª—è LLaVA: {len(base64_image)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º data URL
            data_url = f"data:image/{image_format};base64,{base64_image}"
            
            system_prompt = """You are an expert image analyzer. Your task is to provide an extremely detailed description of the image in English.

CRITICAL REQUIREMENTS - you MUST describe ALL of the following in detail:

1. COLORS - Describe every color you see:
   - Main colors of all objects
   - Secondary colors and accents
   - Color tones and shades (light, dark, bright, muted)
   - Color distribution across the image
   - Any color gradients or transitions

2. MATERIALS - Identify and describe materials of ALL objects:
   - Surface materials (wood, metal, plastic, fabric, stone, glass, etc.)
   - Material textures (smooth, rough, glossy, matte, reflective, etc.)
   - Material properties (transparent, opaque, shiny, dull, etc.)
   - Material condition (new, old, worn, polished, etc.)

3. OBJECTS - List and describe ALL objects:
   - What objects are in the image
   - Their sizes and proportions
   - Their positions and arrangement
   - Their relationships to each other

4. COMPOSITION:
   - Overall layout and arrangement
   - Foreground, middle ground, background
   - Perspective and angle
   - Focal points

5. LIGHTING:
   - Light sources and direction
   - Shadows and highlights
   - Overall lighting mood (bright, dim, dramatic, etc.)

6. STYLE AND ATMOSPHERE:
   - Overall style (realistic, artistic, etc.)
   - Mood and atmosphere
   - Any special effects or filters

EXAMPLE OF A GOOD DESCRIPTION:
"A wooden fence in the foreground, painted in a dark brown color with a matte finish. The wood grain is visible, showing a rough, weathered texture. The fence consists of vertical wooden planks approximately 2 meters tall, with horizontal support beams. The material appears to be aged wood with some wear and minor cracks. The fence is positioned in the center of the image, extending horizontally across the frame. In the background, there is a green grassy field under a bright blue sky with white clouds. The lighting is natural daylight from above, casting soft shadows on the ground. The overall style is photorealistic with a warm, sunny atmosphere."

Be extremely thorough and specific. Your description will be used to transform this image, so every detail matters. Write in English, be very detailed, and mention EVERYTHING you see. Use professional English terminology for colors, materials, and composition.

After your description, add a brief completeness check:
- [‚úì] Colors described
- [‚úì] Materials identified
- [‚úì] Objects listed
- [‚úì] Composition noted
- [‚úì] Lighting described"""
            
            # –î–ª—è Ollama LLaVA –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç —Å –ø–æ–ª–µ–º "images" –¥–ª—è base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            user_message_text = """Describe this image in extreme detail in English.

MANDATORY - you MUST describe:
1. ALL colors - every color of every object, shades, brightness, saturation
2. ALL materials - what each object is made of (wood, metal, plastic, fabric, stone, glass, concrete, etc.)
3. Material textures - smooth, rough, glossy, matte, reflective, matte, porous, etc.
4. ALL objects - what is in the image, their sizes, proportions, and positions
5. Composition - how objects are arranged, foreground, middle ground, background, perspective
6. Lighting - light sources, direction, shadows, highlights, overall lighting mood
7. Style and atmosphere - overall style, mood, any special effects

Be extremely detailed and precise. Your description will be used to transform this image, so every detail matters. Use professional English terminology."""
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç—Ä–µ–±—É–µ–º—É—é VRAM –¥–ª—è LLaVA (—É–º–µ–Ω—å—à–µ–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã)
            # 5GB –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è llava:13b –Ω–∞ 6GB GPU –ø—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–∏ VRAM
            estimated_vram_mb = 5120  # 5GB –¥–ª—è llava:13b
            
            # –î–ª—è LLaVA —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ Ollama, —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å VRAM –æ—Ç gpt-oss
            # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ llava:13b —Å–º–æ–∂–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è –±–µ–∑ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
            logger.info(f"üîÑ LLaVA —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ Ollama –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è VRAM –æ—Ç gpt-oss...")
            
            try:
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º Ollama –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º GPU –¥–ª—è LLaVA
                # –≠—Ç–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç gpt-oss –∏ –æ—Å–≤–æ–±–æ–¥–∏—Ç VRAM
                api_available = await process_manager_service.check_api_available()
                if api_available:
                    logger.info(f"üõë –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLaVA...")
                    try:
                        async with httpx.AsyncClient(timeout=10.0) as client:
                            # –ù–æ–≤—ã–π API: /stop/ollama
                            stop_response = await client.post(
                                f"{process_manager_service.api_url}/stop/ollama"
                            )
                            if stop_response.status_code == 404:
                                # –§–æ–ª–±–µ–∫ –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ API
                                stop_response = await client.post(
                                    f"{process_manager_service.api_url}/process/stop",
                                    params={"service": "ollama"}
                                )
                            if stop_response.status_code == 200:
                                logger.info(f"‚úÖ Ollama –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –æ–∂–∏–¥–∞–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è VRAM (3 —Å–µ–∫—É–Ω–¥—ã)...")
                                await asyncio.sleep(3)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ VRAM
                            else:
                                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Ollama: {stop_response.status_code}")
                    except Exception as stop_error:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ Ollama: {stop_error}")
                
                async with await resource_manager.acquire_gpu(
                    service_type=ServiceType.OLLAMA,
                    user_id=user_id,
                    required_vram_mb=estimated_vram_mb,
                    timeout=60
                ) as gpu_lock:
                    logger.info(f"üîí GPU –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è Ollama (–∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLaVA, ID: {gpu_lock.lock_id[:8]})")
                    
                    # –î–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–µ –≤—Ä–µ–º—è –Ω–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é Ollama –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
                    await asyncio.sleep(2)
                    
                    # Retry –º–µ—Ö–∞–Ω–∏–∑–º —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π (3 –ø–æ–ø—ã—Ç–∫–∏)
                    max_retries = 3
                    retry_delay = 2  # –ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                    last_error = None
                    
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è
                    # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑-–∑–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –≤ –ø–∞–º—è—Ç—å
                    base_timeout = float(settings.OLLAMA_VISION_TIMEOUT)
                    
                    for attempt in range(max_retries):
                        try:
                            # –î–ª—è –ø–µ—Ä–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç, —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è
                            if attempt == 0:
                                timeout_value = max(base_timeout, 180.0)  # –ú–∏–Ω–∏–º—É–º 180 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø–µ—Ä–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏
                                logger.info(f"üîÑ –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º {timeout_value}s (–º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è)")
                            else:
                                timeout_value = base_timeout
                            
                            # httpx —Ç—Ä–µ–±—É–µ—Ç float –¥–ª—è —Ç–∞–π–º–∞—É—Ç–∞ –∏–ª–∏ –æ–±—ä–µ–∫—Ç httpx.Timeout
                            async with httpx.AsyncClient(timeout=timeout_value) as client:
                                # –î–ª—è Ollama LLaVA —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ –ø–æ–ª–µ "images" –∫–∞–∫ –º–∞—Å—Å–∏–≤ base64 —Å—Ç—Ä–æ–∫
                                payload = {
                                    "model": settings.OLLAMA_VISION_MODEL,
                                    "messages": [
                                        {
                                            "role": "system",
                                            "content": system_prompt
                                        },
                                        {
                                            "role": "user",
                                            "content": user_message_text,
                                            "images": [base64_image]  # Ollama –æ–∂–∏–¥–∞–µ—Ç –º–∞—Å—Å–∏–≤ base64 —Å—Ç—Ä–æ–∫ –≤ –ø–æ–ª–µ "images"
                                        }
                                    ],
                                    "stream": False
                                }
                                
                                logger.info(f"üîÑ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLaVA (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}, —Ç–∞–π–º–∞—É—Ç: {timeout_value}s, —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {len(image_bytes)} –±–∞–π—Ç, —Ä–∞–∑–º–µ—Ä base64: {len(base64_image)} —Å–∏–º–≤–æ–ª–æ–≤)")
                                logger.debug(f"   URL: {self.ollama_url}/api/chat")
                                logger.debug(f"   –ú–æ–¥–µ–ª—å: {settings.OLLAMA_VISION_MODEL}")
                                request_start_time = time.time()
                                try:
                                    response = await client.post(
                                        f"{self.ollama_url}/api/chat",
                                        json=payload
                                    )
                                    request_time = time.time() - request_start_time
                                    logger.info(f"üìä –û—Ç–≤–µ—Ç –æ—Ç LLaVA –ø–æ–ª—É—á–µ–Ω –∑–∞ {request_time:.2f}s (—Å—Ç–∞—Ç—É—Å: {response.status_code})")
                                except httpx.TimeoutException as timeout_err:
                                    request_time = time.time() - request_start_time
                                    logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ LLaVA –ø–æ—Å–ª–µ {request_time:.2f}s (—Ç–∞–π–º–∞—É—Ç –±—ã–ª {timeout_value}s)")
                                    raise
                                
                                if response.status_code == 200:
                                    result = response.json()
                                    description = result.get("message", {}).get("content", "")
                                    
                                    if description:
                                        logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ LLaVA (–¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è: {len(description)} —Å–∏–º–≤–æ–ª–æ–≤, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                                        logger.debug(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {description[:200]}...")
                                        
                                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ—Ç—É –æ–ø–∏—Å–∞–Ω–∏—è
                                        validation = self._validate_image_description(description)
                                        if not validation["complete"]:
                                            logger.warning(f"‚ö†Ô∏è –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–ø–æ–ª–Ω–æ–µ, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(validation['missing_categories'])}")
                                        else:
                                            logger.info(f"‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–µ, –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                                        
                                        return {
                                            "description": description.strip(),
                                            "success": True,
                                            "error": None,
                                            "validation": validation
                                        }
                                    else:
                                        logger.warning(f"‚ö†Ô∏è LLaVA –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                                        if attempt < max_retries - 1:
                                            await asyncio.sleep(retry_delay * (2 ** attempt))  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                                            continue
                                        return {
                                            "description": "",
                                            "success": False,
                                            "error": "LLaVA –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫"
                                        }
                                else:
                                    error_msg = f"–û—à–∏–±–∫–∞ Ollama API: {response.status_code} - {response.text}"
                                    logger.warning(f"‚ö†Ô∏è {error_msg} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                                    last_error = error_msg
                                    if attempt < max_retries - 1:
                                        await asyncio.sleep(retry_delay * (2 ** attempt))  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                                        continue
                                    
                        except httpx.TimeoutException as e:
                            last_error = f"–¢–∞–π–º–∞—É—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (>{settings.OLLAMA_VISION_TIMEOUT}s)"
                            logger.warning(f"‚ö†Ô∏è {last_error} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å Ollama (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
                            ollama_available = await process_manager_service.check_service_available(ServiceType.OLLAMA)
                            if not ollama_available:
                                logger.error(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ —Ç–∞–π–º–∞—É—Ç–∞")
                                # –ù–ï –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –∑–¥–µ—Å—å - –ø—É—Å—Ç—å Resource Manager –∏–ª–∏ Process Manager —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
                            
                            if attempt < max_retries - 1:
                                await asyncio.sleep(retry_delay * (2 ** attempt))  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                                continue
                        except (httpx.ConnectError, httpx.ConnectTimeout) as e:
                            last_error = f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama: {e}"
                            logger.error(f"‚ùå {last_error} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—Ü–µ—Å—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
                            ollama_available = await process_manager_service.check_service_available(ServiceType.OLLAMA)
                            if not ollama_available:
                                logger.error(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                                # –ù–ï –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –∑–¥–µ—Å—å - –ø—É—Å—Ç—å Resource Manager –∏–ª–∏ Process Manager —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
                            
                            if attempt < max_retries - 1:
                                await asyncio.sleep(retry_delay * (2 ** attempt))  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                                continue
                        except Exception as e:
                            last_error = str(e)
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—Ü–µ—Å—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
                            ollama_available = await process_manager_service.check_service_available(ServiceType.OLLAMA)
                            if not ollama_available:
                                logger.error(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏")
                                # –ù–ï –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –∑–¥–µ—Å—å - –ø—É—Å—Ç—å Resource Manager –∏–ª–∏ Process Manager —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
                            
                            if attempt < max_retries - 1:
                                await asyncio.sleep(retry_delay * (2 ** attempt))  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                                continue
                    
                    # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {last_error}")
                    return {
                        "description": "",
                        "success": False,
                        "error": f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {last_error}"
                    }
                        
            except TimeoutError as e:
                logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU –¥–ª—è Ollama (–∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è): {e}")
                return {
                    "description": "",
                    "success": False,
                    "error": f"–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU: {str(e)}",
                    "error_type": "gpu_timeout"
                }
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Resource Manager (–∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è): {e}")
                return {
                    "description": "",
                    "success": False,
                    "error": f"–û—à–∏–±–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–∞–º–∏: {str(e)}",
                    "error_type": "resource_error"
                }
                
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}", exc_info=True)
            return {
                "description": "",
                "success": False,
                "error": f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
            }
    
    async def analyze_img2img_settings(self, description: str, user_id: Optional[int] = None, image_description: Optional[str] = None) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ KSampler –¥–ª—è img-to-img
        
        Args:
            description: –û–ø–∏—Å–∞–Ω–∏–µ –∂–µ–ª–∞–µ–º–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–∏)
            image_description: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç LLaVA (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ KSampler:
            {
                "denoise": float,  # 0.4-0.9
                "steps": int,      # 25-40
                "cfg": float,      # 1.0 (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ –¥–ª—è FLUX)
                "sampler_name": str,  # "euler" –∏–ª–∏ "dpmpp_2m_karras"
                "success": bool,
                "error": Optional[str]
            }
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # –î–ª—è Flux.1-dev –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π denoise: 0.55-0.65 (–Ω–µ 0.8-0.9!)
        if image_description:
            system_prompt = f"""You are an expert in AI image generation settings for Flux.1-dev model img-to-img tasks.
Your task is to analyze the user's description and determine optimal KSampler settings, especially the denoise level.

CURRENT IMAGE DESCRIPTION (from visual analysis):
{image_description}

USER REQUEST:
{description}

You know what the current image looks like and what the user wants to change. Based on this, determine the level of transformation needed.

CRITICAL FOR FLUX.1-DEV: For SIGNIFICANT changes (age, face, major transformations), use denoise 0.75-0.8. For moderate changes, use 0.65-0.75.

You need to determine:
1. Denoise level (0.4-0.8): How much to change the original image
   CRITICAL FOR FLUX.1-DEV - Determine transformation intensity:
   - STRONG TRANSFORMATION (0.75-0.8): Fundamental characteristic changes
     * Appearance/age modifications (any subject: people, animals, objects with age characteristics)
     * Complete structural transformations (changing object type or major features)
     * Complete color/material reversals (opposite colors, completely different materials)
     * Major feature modifications (removing/adding significant elements)
   
   - STRONG CHANGE (0.7-0.75): Significant modifications
     * Major color changes (dominant color replacement)
     * Material type swaps (wood‚Üîmetal, stone‚Üîglass, fabric‚Üîleather, etc.)
     * Object removal/addition (removing/adding visible objects)
     * Significant style changes
   
   - MODERATE CHANGE (0.65-0.7): Moderate modifications
     * Color tinting/adjustments (not complete replacement)
     * Style refinements
     * Subtle material adjustments
   
   - MINOR CHANGE (0.4-0.55): Subtle adjustments
     * Quality improvements
     * Minor corrections
     * Slight enhancements
   
   IMPORTANT: For Flux.1-dev, denoise 0.75 is SAFE and provides STRONG transformations while maintaining image structure.
   For significant changes (age, face, major color/material changes), use 0.75-0.8.
   DEFAULT: For significant transformations, use 0.75.
   
2. Steps (25-40): Number of sampling steps (default 30)
   - Use 25-28 for faster generation with good quality
   - Use 30-35 for balanced quality and speed
   - Use 36-40 for highest quality (slower)

3. CFG Scale: Always 1.0 for FLUX models (fixed)

4. Sampler: "euler" (default for img-to-img, works well with Flux) or "dpmpp_2m_karras"

Return ONLY valid JSON in this exact format:
{{
  "denoise": 0.75,
  "steps": 30,
  "cfg": 1.0,
  "sampler_name": "euler"
}}

Decision principles (FOR FLUX.1-DEV):
- STRONG TRANSFORMATION (0.75-0.8): When the request requires changing fundamental characteristics (appearance, age, major structural changes, complete color/material replacement). Examples: changing age/appearance, transforming object type, complete color reversal (black->white).
- STRONG CHANGE (0.7-0.75): When significant modifications are needed (major color changes, material swaps, object removal/addition). Examples: changing dominant color, replacing material type, removing/adding objects.
- MODERATE CHANGE (0.65-0.7): When moderate modifications are needed (color adjustments, style changes). Examples: color tinting, style modifications.
- MINOR CHANGE (0.4-0.55): When only subtle adjustments are needed. Examples: quality improvements, minor corrections.

Analyze the request and current image to determine the transformation level needed.

Do not include any text before or after the JSON. Only return the JSON object."""
            user_message = f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–ø—Ä–µ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ KSampler –¥–ª—è Flux.1-dev:\n\n–¢–µ–∫—É—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_description}\n\n–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {description}"
        else:
            system_prompt = """You are an expert in AI image generation settings for Flux.1-dev model img-to-img tasks.
Your task is to analyze the user's description and determine optimal KSampler settings, especially the denoise level.

CRITICAL FOR FLUX.1-DEV: For SIGNIFICANT changes (age, face, major transformations), use denoise 0.75-0.8. For moderate changes, use 0.65-0.75.

The user wants to modify an existing image based on their description. You need to determine:
1. Denoise level (0.4-0.8): How much to change the original image
   CRITICAL FOR FLUX.1-DEV - –û–ø—Ä–µ–¥–µ–ª–∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏:
   - –°–ò–õ–¨–ù–ê–Ø –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–Ø (0.75-0.8): –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
     * –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≤–Ω–µ—à–Ω–µ–≥–æ –≤–∏–¥–∞/–≤–æ–∑—Ä–∞—Å—Ç–∞ (–ª—é–±–æ–π –æ–±—ä–µ–∫—Ç: –ª—é–¥–∏, –∂–∏–≤–æ—Ç–Ω—ã–µ, –ø—Ä–µ–¥–º–µ—Ç—ã —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞)
     * –ü–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è (–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ç–∏–ø–∞ –æ–±—ä–µ–∫—Ç–∞ –∏–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
     * –ü–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ —Ü–≤–µ—Ç–∞/–º–∞—Ç–µ—Ä–∏–∞–ª–∞ (–ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–µ —Ü–≤–µ—Ç–∞, —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã)
     * –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—É–¥–∞–ª–µ–Ω–∏–µ/–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
   
   - –°–ò–õ–¨–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï (0.7-0.75): –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
     * –ö—Ä—É–ø–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–≤–µ—Ç–∞ (–∑–∞–º–µ–Ω–∞ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–≥–æ —Ü–≤–µ—Ç–∞)
     * –ó–∞–º–µ–Ω–∞ —Ç–∏–ø–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ (–¥–µ—Ä–µ–≤–æ‚Üî–º–µ—Ç–∞–ª–ª, –∫–∞–º–µ–Ω—å‚Üî—Å—Ç–µ–∫–ª–æ, —Ç–∫–∞–Ω—å‚Üî–∫–æ–∂–∞ –∏ —Ç.–¥.)
     * –£–¥–∞–ª–µ–Ω–∏–µ/–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ (—É–¥–∞–ª–µ–Ω–∏–µ/–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∏–¥–∏–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤)
     * –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∏–ª—è
   
   - –£–ú–ï–†–ï–ù–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï (0.65-0.7): –£–º–µ—Ä–µ–Ω–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
     * –¢–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ/–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ü–≤–µ—Ç–∞ (–Ω–µ –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞)
     * –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Å—Ç–∏–ª—è
     * –ù–µ–±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞
   
   - –ù–ï–ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï (0.4-0.55): –ù–µ–±–æ–ª—å—à–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏
     * –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
     * –ù–µ–±–æ–ª—å—à–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
     * –õ–µ–≥–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
   
   IMPORTANT: For Flux.1-dev, denoise 0.75 is SAFE and provides STRONG transformations while maintaining image structure.
   For significant changes (age, face, major color/material changes), use 0.75-0.8.
   DEFAULT: For significant transformations, use 0.75.
   
2. Steps (25-30): Number of sampling steps (default 30)
   - Use 25-28 for faster generation with good quality
   - Use 30 for balanced quality and speed
   - Flux.1-dev usually doesn't need more than 30 steps

3. CFG Scale: Always 1.0 for FLUX models (fixed)

4. Sampler: "euler" (default for img-to-img, works well with Flux.1-dev)

Return ONLY valid JSON in this exact format:
{
  "denoise": 0.75,
  "steps": 30,
  "cfg": 1.0,
  "sampler_name": "euler"
}

Decision principles (FOR FLUX.1-DEV):
Analyze the request to determine the transformation intensity:

- STRONG TRANSFORMATION (0.75-0.8): Requests that require changing fundamental characteristics:
  * Appearance/age changes (younger, older, different appearance)
  * Complete structural transformations (object type changes)
  * Complete color/material reversals (opposite colors, completely different materials)
  * Major feature modifications (removing/adding significant elements)

- STRONG CHANGE (0.7-0.75): Requests that require significant modifications:
  * Major color changes (dominant color replacement)
  * Material type swaps (wood to metal, stone to glass, etc.)
  * Object removal/addition (removing/adding visible objects)
  * Significant style changes

- MODERATE CHANGE (0.65-0.7): Requests that require moderate modifications:
  * Color tinting/adjustments (not complete replacement)
  * Style refinements
  * Subtle material adjustments

- MINOR CHANGE (0.4-0.55): Requests that require only subtle adjustments:
  * Quality improvements
  * Minor corrections
  * Slight enhancements

Apply these principles to any request, regardless of subject (people, objects, scenes, etc.).

Do not include any text before or after the JSON. Only return the JSON object."""
            user_message = f"–û–ø—Ä–µ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ KSampler –¥–ª—è img-to-img –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è:\n\n{description}"
        
        estimated_vram_mb = 2048
        
        try:
            async with await resource_manager.acquire_gpu(
                service_type=ServiceType.OLLAMA,
                user_id=user_id,
                required_vram_mb=estimated_vram_mb,
                timeout=60
            ) as gpu_lock:
                logger.info(f"üîí GPU –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è Ollama (–∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ img-to-img, ID: {gpu_lock.lock_id[:8]})")
                
                try:
                    async with httpx.AsyncClient(timeout=60.0) as client:
                        payload = {
                            "model": self.model,
                            "messages": [
                                {
                                    "role": "system",
                                    "content": system_prompt
                                },
                                {
                                    "role": "user",
                                    "content": user_message
                                }
                            ],
                            "stream": False,
                            "format": "json"
                        }
                        
                        response = await client.post(
                            f"{self.ollama_url}/api/chat",
                            json=payload
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            content = result.get("message", {}).get("content", "")
                            
                            try:
                                # –£–±–∏—Ä–∞–µ–º markdown code blocks, –µ—Å–ª–∏ –µ—Å—Ç—å
                                content = content.strip()
                                if content.startswith("```"):
                                    lines = content.split("\n")
                                    if lines[0].startswith("```"):
                                        lines = lines[1:]
                                    if lines[-1].strip() == "```":
                                        lines = lines[:-1]
                                    content = "\n".join(lines)
                                
                                settings_data = json.loads(content)
                                
                                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è Flux.1-dev
                                # Fallback —É–≤–µ–ª–∏—á–µ–Ω –¥–æ 0.75 –¥–ª—è –±–æ–ª–µ–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
                                denoise = float(settings_data.get("denoise", 0.75))
                                description_lower = description.lower()
                                
                                # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞/–ª–∏—Ü–∞ (–Ω—É–∂–µ–Ω –±–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–π denoise)
                                age_keywords = [
                                    "–º–æ–ª–æ–¥", "–º–ª–∞–¥—à–µ", "–ø–æ—Å—Ç–∞—Ä", "—Å—Ç–∞—Ä—à–µ", "–≤–æ–∑—Ä–∞—Å—Ç", "–æ–º–æ–ª–æ–¥",
                                    "–º–æ—Ä—â–∏–Ω", "—Å–µ–¥", "—Å–µ–¥–∏–Ω", "–±–æ—Ä–æ–¥", "–ª–∏—Ü–æ", "–∫–æ–∂–∞",
                                    "younger", "older", "age", "wrinkle", "wrinkles", "face", "skin", "beard", "gray hair"
                                ]
                                
                                # –î–ª—è Flux.1-dev –±–∞–∑–æ–≤—ã–π –º–∞–∫—Å–∏–º—É–º denoise: 0.75 (—É–≤–µ–ª–∏—á–µ–Ω –¥–ª—è –±–æ–ª–µ–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π)
                                # –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç–∞/–ª–∏—Ü–∞ –¥–æ–ø—É—Å–∫–∞–µ–º –¥–æ 0.8 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
                                max_denoise = 0.8 if any(keyword in description_lower for keyword in age_keywords) else 0.75
                                # –ú–∏–Ω–∏–º—É–º —Ç–∞–∫–∂–µ —É–≤–µ–ª–∏—á–µ–Ω –¥–ª—è –±–æ–ª–µ–µ –∑–∞–º–µ—Ç–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
                                min_denoise = 0.6 if any(keyword in description_lower for keyword in age_keywords) else 0.55
                                denoise = max(min_denoise, min(max_denoise, denoise))
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞
                                color_keywords = ["–±–µ–ª—ã–π", "–∫—Ä–∞—Å–Ω—ã–π", "—Å–∏–Ω–∏–π", "—á–µ—Ä–Ω—ã–π", "–∑–µ–ª–µ–Ω—ã–π", "–∂–µ–ª—Ç—ã–π", "–æ—Ä–∞–Ω–∂–µ–≤—ã–π",
                                                 "—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π", "—Ä–æ–∑–æ–≤—ã–π", "–∫–æ—Ä–∏—á–Ω–µ–≤—ã–π", "—Å–µ—Ä—ã–π", "–≥–æ–ª—É–±–æ–π", "—Ü–≤–µ—Ç",
                                                 "–ø–æ–∫—Ä–∞—Å–∏—Ç—å", "–æ–∫—Ä–∞—Å–∏—Ç—å", "—Å–¥–µ–ª–∞—Ç—å –±–µ–ª—ã–π", "—Å–¥–µ–ª–∞—Ç—å –∫—Ä–∞—Å–Ω—ã–π",
                                                 "–∏–∑–º–µ–Ω–∏—Ç—å —Ü–≤–µ—Ç", "–ø–æ–º–µ–Ω—è—Ç—å —Ü–≤–µ—Ç", "–¥—Ä—É–≥–æ–π —Ü–≤–µ—Ç"]
                                
                                if any(keyword in description_lower for keyword in color_keywords):
                                    # –î–ª—è Flux.1-dev –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π denoise –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–≤–µ—Ç–∞: 0.65-0.75 (—É–≤–µ–ª–∏—á–µ–Ω –¥–ª—è –ª—É—á—à–µ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞)
                                    denoise = max(0.65, min(0.75, denoise))
                                    logger.info(f"üé® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω denoise: {denoise} (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è Flux.1-dev)")
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
                                elif denoise < 0.65:
                                    significant_keywords = ["–∏–∑–º–µ–Ω–∏—Ç—å", "–ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å", "—É–±—Ä–∞—Ç—å", "–¥–æ–±–∞–≤–∏—Ç—å", 
                                                          "–∑–∞–º–µ–Ω–∏—Ç—å", "—Å–¥–µ–ª–∞—Ç—å", "–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π", "–º–µ—Ç–∞–ª–ª–∏—á–µ—Å–∫–∏–π",
                                                          "–∫–∞–º–µ–Ω–Ω—ã–π", "—Å—Ç–µ–∫–ª—è–Ω–Ω—ã–π"]
                                    if any(keyword in description_lower for keyword in significant_keywords):
                                        denoise = max(0.65, denoise)  # –ú–∏–Ω–∏–º—É–º 0.65 –¥–ª—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ Flux.1-dev
                                
                                steps = int(settings_data.get("steps", 30))
                                # –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç–∞/–ª–∏—Ü–∞ –Ω–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —à–∞–≥–∏
                                if any(keyword in description_lower for keyword in age_keywords):
                                    steps = max(35, steps)
                                steps = max(25, min(40, steps))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
                                
                                cfg = float(settings_data.get("cfg", 1.0))
                                cfg = 1.0  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ –¥–ª—è FLUX
                                
                                sampler_name = settings_data.get("sampler_name", "euler")
                                if sampler_name not in ["dpmpp_2m_karras", "euler", "dpmpp_2m", "euler_ancestral"]:
                                    sampler_name = "euler"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é euler –¥–ª—è img-to-img (–∫–∞–∫ –≤ —à–∞–±–ª–æ–Ω–µ)
                                
                                logger.info(f"‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ KSampler –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã: denoise={denoise}, steps={steps}, cfg={cfg}, sampler={sampler_name}")
                                
                                return {
                                    "denoise": denoise,
                                    "steps": steps,
                                    "cfg": cfg,
                                    "sampler_name": sampler_name,
                                    "success": True,
                                    "error": None
                                }
                                
                            except (json.JSONDecodeError, ValueError, KeyError) as e:
                                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ KSampler: {e}")
                                logger.debug(f"–û—Ç–≤–µ—Ç –æ—Ç Ollama: {content[:500]}")
                                
                                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è Flux.1-dev
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞/–ª–∏—Ü–∞
                                description_lower = description.lower()
                                age_keywords = [
                                    "–º–æ–ª–æ–¥", "–º–ª–∞–¥—à–µ", "–ø–æ—Å—Ç–∞—Ä", "—Å—Ç–∞—Ä—à–µ", "–≤–æ–∑—Ä–∞—Å—Ç", "–æ–º–æ–ª–æ–¥",
                                    "–º–æ—Ä—â–∏–Ω", "—Å–µ–¥", "—Å–µ–¥–∏–Ω", "–±–æ—Ä–æ–¥", "–ª–∏—Ü–æ", "–∫–æ–∂–∞",
                                    "younger", "older", "age", "wrinkle", "wrinkles", "face", "skin", "beard", "gray hair"
                                ]
                                # –î–ª—è Flux.1-dev –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π denoise: 0.6, –Ω–æ –¥–ª—è –≤–æ–∑—Ä–∞—Å—Ç–∞/–ª–∏—Ü–∞ –ø–æ–≤—ã—à–∞–µ–º –¥–æ 0.7
                                default_denoise = 0.7 if any(keyword in description_lower for keyword in age_keywords) else 0.6
                                return {
                                    "denoise": default_denoise,
                                    "steps": 30,
                                    "cfg": 1.0,
                                    "sampler_name": "euler",
                                    "success": True,
                                    "error": f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è Flux.1-dev (–æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)})"
                                }
                                
                        else:
                            error_msg = f"–û—à–∏–±–∫–∞ Ollama API: {response.status_code} - {response.text}"
                            logger.error(f"‚ùå {error_msg}")
                            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—É–≤–µ–ª–∏—á–µ–Ω denoise –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)
                            return {
                                "denoise": 0.6,
                                "steps": 30,
                                "cfg": 1.0,
                                "sampler_name": "dpmpp_2m",
                                "success": True,
                                "error": f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ({error_msg})"
                            }
                            
                except httpx.TimeoutException:
                    logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama")
                    return {
                        "denoise": 0.7,
                        "steps": 30,
                        "cfg": 1.0,
                        "sampler_name": "dpmpp_2m",
                        "success": True,
                        "error": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—Ç–∞–π–º–∞—É—Ç)"
                    }
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫: {e}")
                    return {
                        "denoise": 0.7,
                        "steps": 30,
                        "cfg": 1.0,
                        "sampler_name": "dpmpp_2m",
                        "success": True,
                        "error": f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ({str(e)})"
                    }
                    
        except TimeoutError as e:
            logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU –¥–ª—è Ollama (–∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫): {e}")
            return {
                "denoise": 0.7,
                "steps": 30,
                "cfg": 1.0,
                "sampler_name": "dpmpp_2m",
                "success": True,
                "error": f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—Ç–∞–π–º–∞—É—Ç GPU: {str(e)})"
            }
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Resource Manager: {e}")
            return {
                "denoise": 0.7,
                "steps": 30,
                "cfg": 1.0,
                "sampler_name": "dpmpp_2m",
                "success": True,
                "error": f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–æ—à–∏–±–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–∞–º–∏: {str(e)})"
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
prompt_service = PromptService()
