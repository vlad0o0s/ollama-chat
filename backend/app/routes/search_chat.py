"""
–†–æ—É—Ç—ã –¥–ª—è —á–∞—Ç–∞ —Å –ø–æ–∏—Å–∫–æ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
"""
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import Optional
import httpx
import json
import asyncio
from ..database import get_db, SessionLocal
from ..models.user import User
from ..models.chat import Chat
from ..models.message import Message
from ..schemas.search import SearchRequest, SearchMetadata
from ..schemas.message import MessageCreate
from ..auth.dependencies import get_current_user
from ..services.search_service import search_service
from ..services.resource_manager import resource_manager
from ..services.service_types import ServiceType
from ..config import settings
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/chat", tags=["search-chat"])


@router.post("/search")
async def chat_with_search(
    request: SearchRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ß–∞—Ç —Å –ø–æ–∏—Å–∫–æ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∑–∞—Ç–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Ollama
    —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–æ–∏—Å–∫–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —á–∞—Ç–∞
    chat = db.query(Chat).filter(
        Chat.id == request.chat_id,
        Chat.user_id == current_user.id
    ).first()
    
    if not chat:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="–ß–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"
        )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_message = Message(
        chat_id=request.chat_id,
        role="user",
        content=request.message
    )
    db.add(user_message)
    db.commit()
    db.refresh(user_message)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
    search_metadata = None
    search_context = ""
    
    if request.use_search:
        try:
            search_result = await search_service.search(request.message)
            search_metadata = SearchMetadata(
                query=search_result["query"],
                sources=search_result["sources"],
                results_count=len(search_result["results"]),
                success=search_result["success"],
                error=search_result.get("error")
            )
            
            if search_result["success"] and search_result["results"]:
                search_context = search_service.format_search_context(search_result)
            else:
                # –ï—Å–ª–∏ –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–∏—Å–∫–∞
                logger.warning(f"–ü–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {request.message}")
        except Exception as e:
            # –ï—Å–ª–∏ –ø–æ–∏—Å–∫ –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            search_metadata = SearchMetadata(
                query=request.message,
                sources=[],
                results_count=0,
                success=False,
                error=str(e)
            )
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Ollama
    # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    previous_messages = db.query(Message).filter(
        Message.chat_id == request.chat_id
    ).order_by(Message.created_at).all()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
    messages_for_llm = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–æ–∏—Å–∫–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
    if search_context:
        messages_for_llm.append({
            "role": "system",
            "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –í—Å–µ–≥–¥–∞ —É–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–æ–∏—Å–∫–∞."
        })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        for msg in previous_messages:
            if msg.id != user_message.id:  # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ —á—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                messages_for_llm.append({
                    "role": msg.role,
                    "content": msg.content
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–∏—Å–∫–∞ –∏ —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
        messages_for_llm.append({
            "role": "user",
            "content": search_context + f"\n\n–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {request.message}"
        })
    else:
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        for msg in previous_messages:
            if msg.id != user_message.id:  # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ —á—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                messages_for_llm.append({
                    "role": msg.role,
                    "content": msg.content
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        messages_for_llm.append({
            "role": "user",
            "content": request.message
        })
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
    async def generate_response():
        assistant_content = ""
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç—Ä–µ–±—É–µ–º—É—é VRAM –¥–ª—è Ollama (–æ–±—ã—á–Ω–æ 2-4GB)
        estimated_vram_mb = 3072  # 3GB –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        
        # –ü–æ–ª—É—á–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É GPU —á–µ—Ä–µ–∑ Resource Manager
        try:
            async with await resource_manager.acquire_gpu(
                service_type=ServiceType.OLLAMA,
                user_id=current_user.id,
                required_vram_mb=estimated_vram_mb,
                timeout=300
            ) as gpu_lock:
                logger.info(f"üîí GPU –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è Ollama (—á–∞—Ç, ID: {gpu_lock.lock_id[:8]})")
                
                try:
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Ollama
                    async with httpx.AsyncClient(timeout=300.0) as client:
                        ollama_url = f"{settings.OLLAMA_URL}/api/chat"
                        
                        payload = {
                            "model": settings.OLLAMA_DEFAULT_MODEL,
                            "messages": messages_for_llm,
                            "stream": True
                        }
                        
                        async with client.stream(
                            "POST",
                            ollama_url,
                            json=payload,
                            headers={"Content-Type": "application/json"},
                            timeout=300.0
                        ) as response:
                            if response.status_code != 200:
                                try:
                                    error_text = await response.aread()
                                    error_msg = error_text.decode() if error_text else "Unknown error"
                                except:
                                    error_msg = f"HTTP {response.status_code}"
                                logger.error(f"–û—à–∏–±–∫–∞ Ollama: {error_msg}")
                                error_data = {
                                    "error": f"–û—à–∏–±–∫–∞ Ollama: {error_msg}",
                                    "done": True
                                }
                                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                                return
                            
                            async for line in response.aiter_lines():
                                if not line.strip():
                                    continue
                                
                                try:
                                    data = json.loads(line)
                                    
                                    if "message" in data and "content" in data["message"]:
                                        content = data["message"]["content"]
                                        assistant_content += content
                                        
                                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞–Ω–∫ –∫–ª–∏–µ–Ω—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ SSE
                                        chunk_data = {
                                            "content": content,
                                            "done": False
                                        }
                                        yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
                                    
                                    if data.get("done", False):
                                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —á–∞–Ω–∫ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                                        final_data = {
                                            "content": "",
                                            "done": True,
                                            "search_metadata": search_metadata.dict() if search_metadata else None
                                        }
                                        yield f"data: {json.dumps(final_data, ensure_ascii=False)}\n\n"
                                        break
                                        
                                except json.JSONDecodeError:
                                    continue
                                except Exception as e:
                                    error_data = {
                                        "error": str(e),
                                        "done": True
                                    }
                                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                                    break
                                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Ollama: {e}")
                    error_data = {
                        "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}",
                        "done": True
                    }
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                    
        except TimeoutError as e:
            logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU –¥–ª—è Ollama (—á–∞—Ç): {e}")
            error_data = {
                "error": f"–¢–∞–π–º–∞—É—Ç –æ–∂–∏–¥–∞–Ω–∏—è GPU: {str(e)}",
                "done": True
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
            return
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Resource Manager: {e}")
            error_data = {
                "error": f"–û—à–∏–±–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–∞–º–∏: {str(e)}",
                "done": True
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –ë–î (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ)
        if assistant_content:
            def save_message():
                db_session = SessionLocal()
                try:
                    assistant_message = Message(
                        chat_id=request.chat_id,
                        role="assistant",
                        content=assistant_content
                    )
                    db_session.add(assistant_message)
                    db_session.commit()
                finally:
                    db_session.close()
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, save_message)
    
    return StreamingResponse(
        generate_response(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

